{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb1d1df4-648a-4fcb-93db-61aec0207c76",
   "metadata": {},
   "source": [
    "### Wordnet Lemmatization\n",
    "    Lemmatization is a linguistic process in NLP that reduces words to their base or root form, known as the lemma, by eliminating inflectional and derivational morphemes (affixes). This process aims to normalize words with different forms (e.g., singular and plural, past and present tense) to a common dictionary form, enabling more effective analysis and comparison.\n",
    "\n",
    "    NLTK provides WordNetLemmatizer class which is a thin wrapper around the wordnet corpus. This class uses morphy() function to the WordNet CopusReader class to find a lemma.\n",
    "\n",
    "#### Q&A, ChatBot, TextSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe62e2fd-5881-49d9-9797-1c8a242bd680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "147de18d-7b40-4497-a2f7-52fb686566b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['eating', 'eats', 'eaten', 'writing', 'write', 'writes', 'programming',\n",
    "         'programmer', 'programs', 'finally', 'finalized', 'history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8683a1c6-c640-4818-9ca8-1d7a186f64fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Nound\n",
      "eating  -------->  eating\n",
      "eats  -------->  eats\n",
      "eaten  -------->  eaten\n",
      "writing  -------->  writing\n",
      "write  -------->  write\n",
      "writes  -------->  writes\n",
      "programming  -------->  programming\n",
      "programmer  -------->  programmer\n",
      "programs  -------->  program\n",
      "finally  -------->  finally\n",
      "finalized  -------->  finalized\n",
      "history  -------->  history\n"
     ]
    }
   ],
   "source": [
    "print('For Nound')\n",
    "for word in words:\n",
    "    print(f'{word}  -------->  {lemmatizer.lemmatize(word)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd4eb693-9036-42c0-bc2f-36a1b46d2a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Verbs\n",
      "eating  -------->  eat\n",
      "eats  -------->  eat\n",
      "eaten  -------->  eat\n",
      "writing  -------->  write\n",
      "write  -------->  write\n",
      "writes  -------->  write\n",
      "programming  -------->  program\n",
      "programmer  -------->  programmer\n",
      "programs  -------->  program\n",
      "finally  -------->  finally\n",
      "finalized  -------->  finalize\n",
      "history  -------->  history\n"
     ]
    }
   ],
   "source": [
    "print('For Verbs')\n",
    "for word in words:\n",
    "    print(f\"{word}  -------->  {lemmatizer.lemmatize(word, pos='v')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4bd3c0b6-0c86-42cf-b37e-7a92b392d397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Adjectives\n",
      "eating  -------->  eating\n",
      "eats  -------->  eats\n",
      "eaten  -------->  eaten\n",
      "writing  -------->  writing\n",
      "write  -------->  write\n",
      "writes  -------->  writes\n",
      "programming  -------->  programming\n",
      "programmer  -------->  programmer\n",
      "programs  -------->  programs\n",
      "finally  -------->  finally\n",
      "finalized  -------->  finalized\n",
      "history  -------->  history\n"
     ]
    }
   ],
   "source": [
    "print('For Adjectives')\n",
    "for word in words:\n",
    "    print(f\"{word}  -------->  {lemmatizer.lemmatize(word, pos='a')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ccf3a9b1-10e3-452c-992c-6b7c47314dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('go', 'fairly', 'sportingly')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('goes', pos='v'), lemmatizer.lemmatize('fairly', pos='v'), lemmatizer.lemmatize('sportingly', pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92359190-032e-4b5d-a3df-527f4b80ceea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
