{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f586bc08-d5ee-4780-829c-4dc3162c8eec",
   "metadata": {},
   "source": [
    "# Kindle Review Analysis\n",
    "##### Inspiration\n",
    "    - Sentimental analysis on reviews.\n",
    "    - Understanding how people rate usefulness of a review /  What factors influence helpfulness of a review.\n",
    "    - Fake review / Outliers\n",
    "    - Best rated product IDs, or similarity between products based."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90f8330-69aa-40f5-9534-25e465662125",
   "metadata": {},
   "source": [
    "## Best practices\n",
    "1. Pre-processing and clearing\n",
    "2. Train Test Split\n",
    "3. BOW, TFIDF, Word2Vec\n",
    "4. Train ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f8ff25-01fd-4702-8154-c1fb67139f1d",
   "metadata": {},
   "source": [
    "### URL FOR DATASET : https://www.kaggle.com/datasets/bharadwaj6/kindle-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24fcc740-3b05-4063-a84b-9f692723843f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>I enjoy vintage books and movies so I enjoyed ...</td>\n",
       "      <td>05 5, 2014</td>\n",
       "      <td>A1F6404F1VG29J</td>\n",
       "      <td>Avidreader</td>\n",
       "      <td>Nice vintage story</td>\n",
       "      <td>1399248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>4</td>\n",
       "      <td>This book is a reissue of an old one; the auth...</td>\n",
       "      <td>01 6, 2014</td>\n",
       "      <td>AN0N05A9LIJEQ</td>\n",
       "      <td>critters</td>\n",
       "      <td>Different...</td>\n",
       "      <td>1388966400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        asin helpful  overall  \\\n",
       "0           0  B000F83SZQ  [0, 0]        5   \n",
       "1           1  B000F83SZQ  [2, 2]        4   \n",
       "\n",
       "                                          reviewText  reviewTime  \\\n",
       "0  I enjoy vintage books and movies so I enjoyed ...  05 5, 2014   \n",
       "1  This book is a reissue of an old one; the auth...  01 6, 2014   \n",
       "\n",
       "       reviewerID reviewerName             summary  unixReviewTime  \n",
       "0  A1F6404F1VG29J   Avidreader  Nice vintage story      1399248000  \n",
       "1   AN0N05A9LIJEQ     critters        Different...      1388966400  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('kindle_reviews.csv')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8d5bec7-9353-48c2-87b3-6498c7dec524",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['reviewText', 'overall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30dea88-4a69-45ba-a108-542364c96d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(10000)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5c6994e-7082-469c-93b1-5f8cf62dc2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 2, 3, 1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## unique values\n",
    "data.overall.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba5e7b11-f07a-4c3f-a76c-00fdbfa022e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    5848\n",
       "4    2547\n",
       "3    1031\n",
       "2     343\n",
       "1     231\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b033d52-fce8-48de-a400-d966cb7416a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    0\n",
       "overall       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79e77a2f-ea58-4d7d-803a-9b9b8c35926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## so, we can remove the null values present in the dataset\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4cd8a74-c3d1-4ae0-8dfe-b7e60a8cfdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    0\n",
       "overall       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## recheck for null values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b480226-fc2e-4d14-bade-daa6c66089a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-Processing and cleaning\n",
    "### positive review 1\n",
    "### negative review 0\n",
    "data['overall'] = data['overall'].apply(lambda x:0 if x<3 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52394b41-920b-4dc6-8453-33e8e4a0d010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9426\n",
       "0     574\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50b54d4d-978b-478e-9fb5-9efc2688e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. lower the cases\n",
    "data['reviewText'] = data['reviewText'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "549e82f6-1ef3-41f6-ba35-119b00b8b90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3055f506-4768-44c0-b065-9632fea1941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove special characters\n",
    "data['reviewText'] = data['reviewText'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', str(x)))\n",
    "\n",
    "# Step 2: Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['reviewText'] = data['reviewText'].apply(lambda x: \" \".join([word for word in x.split() if word.lower() not in stop_words]))\n",
    "\n",
    "# Step 3: Remove URLs\n",
    "data['reviewText'] = data['reviewText'].apply(lambda x: re.sub(r'(http|https|ftp|ssh)://[\\w_-]+(?:\\.[\\w_-]+)+[\\w.,@?^=%&:/~+#-]*', '', str(x)))\n",
    "\n",
    "# Step 4: Remove HTML tags\n",
    "data['reviewText'] = data['reviewText'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())\n",
    "\n",
    "# Step 5: Remove extra spaces\n",
    "data['reviewText'] = data['reviewText'].apply(lambda x: \" \".join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88c82f56-f5a1-4eb1-8788-d2b23da71477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>367334</th>\n",
       "      <td>im opinion story good like characters even lea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315361</th>\n",
       "      <td>leather lace rocknroll interesting story roman...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729208</th>\n",
       "      <td>love love love author awakened series keeps ge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327736</th>\n",
       "      <td>short story characterization plot resolution c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705292</th>\n",
       "      <td>losing control sexy good read strong alpha alw...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  overall\n",
       "367334  im opinion story good like characters even lea...        1\n",
       "315361  leather lace rocknroll interesting story roman...        1\n",
       "729208  love love love author awakened series keeps ge...        1\n",
       "327736  short story characterization plot resolution c...        0\n",
       "705292  losing control sexy good read strong alpha alw...        1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d07bbda-e0cf-418b-86c1-381f21187b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## applying word net leematization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33c9df5c-c553-4977-b4a9-8bc9465d907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "170a3fea-cf06-4bc4-9f76-85d1ed0e8735",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviewText'] = data['reviewText'].apply(lambda x:lemmatize_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "316771f3-cc7b-4ff4-9c35-614caddec513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>367334</th>\n",
       "      <td>im opinion story good like character even lead...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315361</th>\n",
       "      <td>leather lace rocknroll interesting story roman...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729208</th>\n",
       "      <td>love love love author awakened series keep get...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327736</th>\n",
       "      <td>short story characterization plot resolution c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705292</th>\n",
       "      <td>losing control sexy good read strong alpha alw...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  overall\n",
       "367334  im opinion story good like character even lead...        1\n",
       "315361  leather lace rocknroll interesting story roman...        1\n",
       "729208  love love love author awakened series keep get...        1\n",
       "327736  short story characterization plot resolution c...        0\n",
       "705292  losing control sexy good read strong alpha alw...        1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ea0b59d-742d-4dc5-b8cf-9202a35092a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train-test-split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x = data['reviewText']\n",
    "y = data['overall']\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b504df7-d9b6-4271-807a-dfcd160f2f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eded6a2f-f49b-4af4-8352-a4902bc6bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bow = bow.fit_transform(x_train).toarray()\n",
    "x_test_bow = bow.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0caa03a-d3c9-4bb4-8902-8084cb20e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer()\n",
    "x_train_tf = tf.fit_transform(x_train).toarray()\n",
    "x_test_tf = tf.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96677516-5a31-4428-b684-a8f63a99bb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tf, x_train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2988d842-449b-4325-8c8c-85632c11981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## naive bayes bow\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_model_bow = GaussianNB().fit(x_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d652c6d4-6bba-4b45-92e1-46971775eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## naive bayes tfidf\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_model_tf = GaussianNB().fit(x_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70c9ba7a-097c-459b-8534-13d72af2f4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98b73a12-36c8-4e22-a667-69ae53b4feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bow = nb_model_bow.predict(x_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a87f65e4-9b3c-4987-b9a8-dae503f08742",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tf = nb_model_tf.predict(x_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77b6f8eb-efb8-484e-9705-7c5ba8f60b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW Accuracy 0.82\n",
      "TFIDF Accuracy 0.82\n"
     ]
    }
   ],
   "source": [
    "## accuracy\n",
    "print(f\"BOW Accuracy {accuracy_score(y_test, y_pred_bow)}\")\n",
    "print(f\"TFIDF Accuracy {accuracy_score(y_test, y_pred_tf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96790476-2ae9-4e31-9907-cd166455c5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
